{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t2-AVwhtE5ug",
        "outputId": "384d76b8-a9cf-4eff-c573-67903224618e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.0.tar.gz (316.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.9/316.9 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.0-py2.py3-none-any.whl size=317425344 sha256=9382ef6989df96c74fd612786f21bc0242c3f6490b8c4e55ee35fabe7a580e9e\n",
            "  Stored in directory: /root/.cache/pip/wheels/41/4e/10/c2cf2467f71c678cfc8a6b9ac9241e5e44a01940da8fbb17fc\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jqjMsirtFBKa"
      },
      "outputs": [],
      "source": [
        "# Import PySpark libraries\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.feature import Imputer\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PTonXRADFHhP"
      },
      "outputs": [],
      "source": [
        "spark = SparkSession.builder.appName(\"EmployeePerformance\").getOrCreate()\n",
        "\n",
        "# Read the Excel file into a Pandas DataFrame\n",
        "excel_file_path = '/content/INX_Future_Inc_Employee_Performance_CDS_Project2_Dataset 1.xls'\n",
        "pandas_df = pd.read_excel(excel_file_path)\n",
        "\n",
        "# Convert the Pandas DataFrame into a PySpark DataFrame\n",
        "df = spark.createDataFrame(pandas_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DpWQ1AwsFOuV",
        "outputId": "e26c0a43-26bf-4f1c-b088-8bb612c3a12f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---+------+-------------------+-------------+---------------+--------------------+-----------------------+----------------+-----------------+--------------------------+-------------+-----------------+-----------+------------------+------------------+--------+------------------------+---------------------------+--------------------------+---------------------+------------------+----------------------------+----------------------------+-----------------------+--------------------+---------+-----------------+\n",
            "|EmpNumber|Age|Gender|EducationBackground|MaritalStatus|  EmpDepartment|          EmpJobRole|BusinessTravelFrequency|DistanceFromHome|EmpEducationLevel|EmpEnvironmentSatisfaction|EmpHourlyRate|EmpJobInvolvement|EmpJobLevel|EmpJobSatisfaction|NumCompaniesWorked|OverTime|EmpLastSalaryHikePercent|EmpRelationshipSatisfaction|TotalWorkExperienceInYears|TrainingTimesLastYear|EmpWorkLifeBalance|ExperienceYearsAtThisCompany|ExperienceYearsInCurrentRole|YearsSinceLastPromotion|YearsWithCurrManager|Attrition|PerformanceRating|\n",
            "+---------+---+------+-------------------+-------------+---------------+--------------------+-----------------------+----------------+-----------------+--------------------------+-------------+-----------------+-----------+------------------+------------------+--------+------------------------+---------------------------+--------------------------+---------------------+------------------+----------------------------+----------------------------+-----------------------+--------------------+---------+-----------------+\n",
            "| E1001000| 32|  Male|          Marketing|       Single|          Sales|     Sales Executive|          Travel_Rarely|              10|                3|                         4|           55|                3|          2|                 4|                 1|      No|                      12|                          4|                        10|                    2|                 2|                          10|                           7|                      0|                   8|       No|                3|\n",
            "| E1001006| 47|  Male|          Marketing|       Single|          Sales|     Sales Executive|          Travel_Rarely|              14|                4|                         4|           42|                3|          2|                 1|                 2|      No|                      12|                          4|                        20|                    2|                 3|                           7|                           7|                      1|                   7|       No|                3|\n",
            "| E1001007| 40|  Male|      Life Sciences|      Married|          Sales|     Sales Executive|      Travel_Frequently|               5|                4|                         4|           48|                2|          3|                 1|                 5|     Yes|                      21|                          3|                        20|                    2|                 3|                          18|                          13|                      1|                  12|       No|                4|\n",
            "| E1001009| 41|  Male|    Human Resources|     Divorced|Human Resources|             Manager|          Travel_Rarely|              10|                4|                         2|           73|                2|          5|                 4|                 3|      No|                      15|                          2|                        23|                    2|                 2|                          21|                           6|                     12|                   6|       No|                3|\n",
            "| E1001010| 60|  Male|          Marketing|       Single|          Sales|     Sales Executive|          Travel_Rarely|              16|                4|                         1|           84|                3|          2|                 1|                 8|      No|                      14|                          4|                        10|                    1|                 3|                           2|                           2|                      2|                   2|       No|                3|\n",
            "| E1001011| 27|  Male|      Life Sciences|     Divorced|    Development|           Developer|      Travel_Frequently|              10|                2|                         4|           32|                3|          3|                 1|                 1|      No|                      21|                          3|                         9|                    4|                 2|                           9|                           7|                      1|                   7|       No|                4|\n",
            "| E1001016| 50|  Male|          Marketing|      Married|          Sales|Sales Representative|          Travel_Rarely|               8|                4|                         4|           54|                3|          1|                 2|                 7|      No|                      15|                          4|                         4|                    2|                 3|                           2|                           2|                      2|                   2|       No|                3|\n",
            "| E1001019| 28|Female|      Life Sciences|       Single|    Development|           Developer|          Travel_Rarely|               1|                2|                         1|           67|                1|          1|                 2|                 7|     Yes|                      13|                          4|                        10|                    4|                 3|                           7|                           7|                      3|                   7|      Yes|                3|\n",
            "| E1001020| 36|Female|      Life Sciences|      Married|    Development|           Developer|             Non-Travel|               8|                3|                         1|           63|                4|          3|                 1|                 9|      No|                      14|                          1|                        10|                    2|                 3|                           8|                           7|                      0|                   5|       No|                3|\n",
            "| E1001021| 38|Female|      Life Sciences|       Single|    Development|           Developer|          Travel_Rarely|               1|                3|                         3|           81|                3|          3|                 3|                 4|     Yes|                      14|                          4|                        10|                    4|                 4|                           1|                           0|                      0|                   0|       No|                3|\n",
            "| E1001022| 44|  Male|            Medical|       Single|    Development|           Developer|             Non-Travel|              24|                3|                         1|           49|                1|          1|                 3|                 2|      No|                      14|                          3|                         9|                    5|                 3|                           5|                           2|                      1|                   4|       No|                3|\n",
            "| E1001024| 47|Female|            Medical|     Divorced|          Sales|     Sales Executive|      Travel_Frequently|               3|                3|                         4|           49|                3|          4|                 3|                 9|     Yes|                      12|                          4|                        28|                    2|                 2|                          22|                           2|                     11|                  13|       No|                3|\n",
            "| E1001025| 30|  Male|          Marketing|     Divorced|          Sales|     Sales Executive|          Travel_Rarely|              27|                5|                         3|           99|                3|          2|                 4|                 7|      No|                      23|                          4|                        10|                    2|                 2|                           8|                           7|                      7|                   7|       No|                4|\n",
            "| E1001027| 29|  Male|      Life Sciences|       Single|          Sales|Sales Representative|          Travel_Rarely|              10|                3|                         3|           99|                3|          1|                 3|                 1|      No|                      11|                          3|                         1|                    6|                 3|                           1|                           0|                      0|                   0|       No|                3|\n",
            "| E1001030| 42|  Male|            Medical|     Divorced|    Development|           Developer|      Travel_Frequently|              19|                3|                         3|           57|                4|          1|                 3|                 6|     Yes|                      12|                          4|                         7|                    2|                 3|                           2|                           2|                      2|                   2|      Yes|                3|\n",
            "| E1001035| 34|Female|            Medical|       Single|    Development|           Developer|          Travel_Rarely|               8|                2|                         2|           96|                3|          2|                 3|                 3|      No|                      11|                          4|                        10|                    2|                 3|                           5|                           1|                      4|                   3|       No|                3|\n",
            "| E1001038| 39|Female|    Human Resources|      Married|Human Resources|     Human Resources|          Travel_Rarely|               3|                3|                         3|           44|                4|          2|                 2|                 9|      No|                      15|                          3|                        12|                    3|                 1|                           8|                           3|                      3|                   6|       No|                3|\n",
            "| E1001040| 56|  Male|            Medical|      Married|    Development|           Developer|          Travel_Rarely|               9|                3|                         3|           81|                3|          4|                 4|                 7|      No|                      11|                          3|                        30|                    1|                 2|                          10|                           7|                      1|                   1|       No|                3|\n",
            "| E1001041| 40|Female|            Medical|       Single|    Development|           Developer|          Travel_Rarely|               2|                1|                         4|           86|                2|          1|                 4|                 0|     Yes|                      20|                          4|                         5|                    2|                 2|                           4|                           2|                      2|                   3|       No|                4|\n",
            "| E1001042| 27|Female|            Medical|       Single|    Development|           Developer|          Travel_Rarely|               7|                3|                         4|           55|                2|          2|                 1|                 8|      No|                      19|                          1|                         9|                    2|                 1|                           7|                           6|                      0|                   7|       No|                3|\n",
            "+---------+---+------+-------------------+-------------+---------------+--------------------+-----------------------+----------------+-----------------+--------------------------+-------------+-----------------+-----------+------------------+------------------+--------+------------------------+---------------------------+--------------------------+---------------------+------------------+----------------------------+----------------------------+-----------------------+--------------------+---------+-----------------+\n",
            "only showing top 20 rows\n",
            "\n",
            "+---------+---+------+-------------------+-------------+---------------+--------------------+-----------------------+----------------+-----------------+--------------------------+-------------+-----------------+-----------+------------------+------------------+--------+------------------------+---------------------------+--------------------------+---------------------+------------------+----------------------------+----------------------------+-----------------------+--------------------+---------+-----------------+\n",
            "|EmpNumber|Age|Gender|EducationBackground|MaritalStatus|  EmpDepartment|          EmpJobRole|BusinessTravelFrequency|DistanceFromHome|EmpEducationLevel|EmpEnvironmentSatisfaction|EmpHourlyRate|EmpJobInvolvement|EmpJobLevel|EmpJobSatisfaction|NumCompaniesWorked|OverTime|EmpLastSalaryHikePercent|EmpRelationshipSatisfaction|TotalWorkExperienceInYears|TrainingTimesLastYear|EmpWorkLifeBalance|ExperienceYearsAtThisCompany|ExperienceYearsInCurrentRole|YearsSinceLastPromotion|YearsWithCurrManager|Attrition|PerformanceRating|\n",
            "+---------+---+------+-------------------+-------------+---------------+--------------------+-----------------------+----------------+-----------------+--------------------------+-------------+-----------------+-----------+------------------+------------------+--------+------------------------+---------------------------+--------------------------+---------------------+------------------+----------------------------+----------------------------+-----------------------+--------------------+---------+-----------------+\n",
            "| E1001000| 32|  Male|          Marketing|       Single|          Sales|     Sales Executive|          Travel_Rarely|              10|                3|                         4|           55|                3|          2|                 4|                 1|      No|                      12|                          4|                        10|                    2|                 2|                          10|                           7|                      0|                   8|       No|                0|\n",
            "| E1001006| 47|  Male|          Marketing|       Single|          Sales|     Sales Executive|          Travel_Rarely|              14|                4|                         4|           42|                3|          2|                 1|                 2|      No|                      12|                          4|                        20|                    2|                 3|                           7|                           7|                      1|                   7|       No|                0|\n",
            "| E1001007| 40|  Male|      Life Sciences|      Married|          Sales|     Sales Executive|      Travel_Frequently|               5|                4|                         4|           48|                2|          3|                 1|                 5|     Yes|                      21|                          3|                        20|                    2|                 3|                          18|                          13|                      1|                  12|       No|                1|\n",
            "| E1001009| 41|  Male|    Human Resources|     Divorced|Human Resources|             Manager|          Travel_Rarely|              10|                4|                         2|           73|                2|          5|                 4|                 3|      No|                      15|                          2|                        23|                    2|                 2|                          21|                           6|                     12|                   6|       No|                0|\n",
            "| E1001010| 60|  Male|          Marketing|       Single|          Sales|     Sales Executive|          Travel_Rarely|              16|                4|                         1|           84|                3|          2|                 1|                 8|      No|                      14|                          4|                        10|                    1|                 3|                           2|                           2|                      2|                   2|       No|                0|\n",
            "| E1001011| 27|  Male|      Life Sciences|     Divorced|    Development|           Developer|      Travel_Frequently|              10|                2|                         4|           32|                3|          3|                 1|                 1|      No|                      21|                          3|                         9|                    4|                 2|                           9|                           7|                      1|                   7|       No|                1|\n",
            "| E1001016| 50|  Male|          Marketing|      Married|          Sales|Sales Representative|          Travel_Rarely|               8|                4|                         4|           54|                3|          1|                 2|                 7|      No|                      15|                          4|                         4|                    2|                 3|                           2|                           2|                      2|                   2|       No|                0|\n",
            "| E1001019| 28|Female|      Life Sciences|       Single|    Development|           Developer|          Travel_Rarely|               1|                2|                         1|           67|                1|          1|                 2|                 7|     Yes|                      13|                          4|                        10|                    4|                 3|                           7|                           7|                      3|                   7|      Yes|                0|\n",
            "| E1001020| 36|Female|      Life Sciences|      Married|    Development|           Developer|             Non-Travel|               8|                3|                         1|           63|                4|          3|                 1|                 9|      No|                      14|                          1|                        10|                    2|                 3|                           8|                           7|                      0|                   5|       No|                0|\n",
            "| E1001021| 38|Female|      Life Sciences|       Single|    Development|           Developer|          Travel_Rarely|               1|                3|                         3|           81|                3|          3|                 3|                 4|     Yes|                      14|                          4|                        10|                    4|                 4|                           1|                           0|                      0|                   0|       No|                0|\n",
            "| E1001022| 44|  Male|            Medical|       Single|    Development|           Developer|             Non-Travel|              24|                3|                         1|           49|                1|          1|                 3|                 2|      No|                      14|                          3|                         9|                    5|                 3|                           5|                           2|                      1|                   4|       No|                0|\n",
            "| E1001024| 47|Female|            Medical|     Divorced|          Sales|     Sales Executive|      Travel_Frequently|               3|                3|                         4|           49|                3|          4|                 3|                 9|     Yes|                      12|                          4|                        28|                    2|                 2|                          22|                           2|                     11|                  13|       No|                0|\n",
            "| E1001025| 30|  Male|          Marketing|     Divorced|          Sales|     Sales Executive|          Travel_Rarely|              27|                5|                         3|           99|                3|          2|                 4|                 7|      No|                      23|                          4|                        10|                    2|                 2|                           8|                           7|                      7|                   7|       No|                1|\n",
            "| E1001027| 29|  Male|      Life Sciences|       Single|          Sales|Sales Representative|          Travel_Rarely|              10|                3|                         3|           99|                3|          1|                 3|                 1|      No|                      11|                          3|                         1|                    6|                 3|                           1|                           0|                      0|                   0|       No|                0|\n",
            "| E1001030| 42|  Male|            Medical|     Divorced|    Development|           Developer|      Travel_Frequently|              19|                3|                         3|           57|                4|          1|                 3|                 6|     Yes|                      12|                          4|                         7|                    2|                 3|                           2|                           2|                      2|                   2|      Yes|                0|\n",
            "| E1001035| 34|Female|            Medical|       Single|    Development|           Developer|          Travel_Rarely|               8|                2|                         2|           96|                3|          2|                 3|                 3|      No|                      11|                          4|                        10|                    2|                 3|                           5|                           1|                      4|                   3|       No|                0|\n",
            "| E1001038| 39|Female|    Human Resources|      Married|Human Resources|     Human Resources|          Travel_Rarely|               3|                3|                         3|           44|                4|          2|                 2|                 9|      No|                      15|                          3|                        12|                    3|                 1|                           8|                           3|                      3|                   6|       No|                0|\n",
            "| E1001040| 56|  Male|            Medical|      Married|    Development|           Developer|          Travel_Rarely|               9|                3|                         3|           81|                3|          4|                 4|                 7|      No|                      11|                          3|                        30|                    1|                 2|                          10|                           7|                      1|                   1|       No|                0|\n",
            "| E1001041| 40|Female|            Medical|       Single|    Development|           Developer|          Travel_Rarely|               2|                1|                         4|           86|                2|          1|                 4|                 0|     Yes|                      20|                          4|                         5|                    2|                 2|                           4|                           2|                      2|                   3|       No|                1|\n",
            "| E1001042| 27|Female|            Medical|       Single|    Development|           Developer|          Travel_Rarely|               7|                3|                         4|           55|                2|          2|                 1|                 8|      No|                      19|                          1|                         9|                    2|                 1|                           7|                           6|                      0|                   7|       No|                0|\n",
            "+---------+---+------+-------------------+-------------+---------------+--------------------+-----------------------+----------------+-----------------+--------------------------+-------------+-----------------+-----------+------------------+------------------+--------+------------------------+---------------------------+--------------------------+---------------------+------------------+----------------------------+----------------------------+-----------------------+--------------------+---------+-----------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.show()\n",
        "from pyspark.sql.functions import when\n",
        "\n",
        "# Assuming you have a DataFrame named 'df'\n",
        "df = df.withColumn(\"PerformanceRating\", when(df[\"PerformanceRating\"] == 4, 1).otherwise(0))\n",
        "df.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8YEAkQJnFY-n"
      },
      "source": [
        "**PREPROCESSING**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6rtldLb1FWGG",
        "outputId": "478b2bc6-5e96-401c-a3e8-12fb6e5b009b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---+------+-------------------+-------------+-------------+----------+-----------------------+----------------+-----------------+--------------------------+-------------+-----------------+-----------+------------------+------------------+--------+------------------------+---------------------------+--------------------------+---------------------+------------------+----------------------------+----------------------------+-----------------------+--------------------+---------+-----------------+\n",
            "|EmpNumber|Age|Gender|EducationBackground|MaritalStatus|EmpDepartment|EmpJobRole|BusinessTravelFrequency|DistanceFromHome|EmpEducationLevel|EmpEnvironmentSatisfaction|EmpHourlyRate|EmpJobInvolvement|EmpJobLevel|EmpJobSatisfaction|NumCompaniesWorked|OverTime|EmpLastSalaryHikePercent|EmpRelationshipSatisfaction|TotalWorkExperienceInYears|TrainingTimesLastYear|EmpWorkLifeBalance|ExperienceYearsAtThisCompany|ExperienceYearsInCurrentRole|YearsSinceLastPromotion|YearsWithCurrManager|Attrition|PerformanceRating|\n",
            "+---------+---+------+-------------------+-------------+-------------+----------+-----------------------+----------------+-----------------+--------------------------+-------------+-----------------+-----------+------------------+------------------+--------+------------------------+---------------------------+--------------------------+---------------------+------------------+----------------------------+----------------------------+-----------------------+--------------------+---------+-----------------+\n",
            "|        0|  0|     0|                  0|            0|            0|         0|                      0|               0|                0|                         0|            0|                0|          0|                 0|                 0|       0|                       0|                          0|                         0|                    0|                 0|                           0|                           0|                      0|                   0|        0|                0|\n",
            "+---------+---+------+-------------------+-------------+-------------+----------+-----------------------+----------------+-----------------+--------------------------+-------------+-----------------+-----------+------------------+------------------+--------+------------------------+---------------------------+--------------------------+---------------------+------------------+----------------------------+----------------------------+-----------------------+--------------------+---------+-----------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.functions import isnan, count,when\n",
        "\n",
        "# Count the number of missing values in each column\n",
        "missing_values_count = df.agg(*[count(when(isnan(c), 1)).alias(c) for c in df.columns])\n",
        "\n",
        "# Display the number of missing values in each column\n",
        "missing_values_count.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YRIrYA3TGN-z",
        "outputId": "1211038c-009b-427b-a59d-b6384eba5f4b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        }
      ],
      "source": [
        "#To check for missing values in a specific column\n",
        "# Check for missing values in the \"Age\" column\n",
        "missing_values_count = df.filter(isnan(df[\"Age\"])).count()\n",
        "\n",
        "# Print the number of missing values\n",
        "print(missing_values_count)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vrF3MSU2GT1f"
      },
      "source": [
        "\n",
        "Convert the categorical features to numerical features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_z1l2oieGS0o"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.feature import StringIndexer, OneHotEncoder\n",
        "from pyspark.ml import Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TAXwKo-YGPzN",
        "outputId": "c808692b-e69d-4aaa-90d9-d939828009de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------+---+----------------+-----------------+--------------------------+-------------+-----------------+-----------+------------------+------------------+------------------------+---------------------------+--------------------------+---------------------+------------------+----------------------------+----------------------------+-----------------------+--------------------+-----------------+------------+-------------------------+-------------------+-------------------+----------------+-----------------------------+--------------+---------------+--------------+---------------------------+---------------------+---------------------+------------------+-------------------------------+----------------+-----------------+\n",
            "|EmpNumber|Age|DistanceFromHome|EmpEducationLevel|EmpEnvironmentSatisfaction|EmpHourlyRate|EmpJobInvolvement|EmpJobLevel|EmpJobSatisfaction|NumCompaniesWorked|EmpLastSalaryHikePercent|EmpRelationshipSatisfaction|TotalWorkExperienceInYears|TrainingTimesLastYear|EmpWorkLifeBalance|ExperienceYearsAtThisCompany|ExperienceYearsInCurrentRole|YearsSinceLastPromotion|YearsWithCurrManager|PerformanceRating|Gender_index|EducationBackground_index|MaritalStatus_index|EmpDepartment_index|EmpJobRole_index|BusinessTravelFrequency_index|OverTime_index|Attrition_index|Gender_encoded|EducationBackground_encoded|MaritalStatus_encoded|EmpDepartment_encoded|EmpJobRole_encoded|BusinessTravelFrequency_encoded|OverTime_encoded|Attrition_encoded|\n",
            "+---------+---+----------------+-----------------+--------------------------+-------------+-----------------+-----------+------------------+------------------+------------------------+---------------------------+--------------------------+---------------------+------------------+----------------------------+----------------------------+-----------------------+--------------------+-----------------+------------+-------------------------+-------------------+-------------------+----------------+-----------------------------+--------------+---------------+--------------+---------------------------+---------------------+---------------------+------------------+-------------------------------+----------------+-----------------+\n",
            "| E1001000| 32|              10|                3|                         4|           55|                3|          2|                 4|                 1|                      12|                          4|                        10|                    2|                 2|                          10|                           7|                      0|                   8|                0|         0.0|                      2.0|                1.0|                1.0|             0.0|                          0.0|           0.0|            0.0| (2,[0],[1.0])|              (5,[2],[1.0])|        (2,[1],[1.0])|        (5,[1],[1.0])|    (18,[0],[1.0])|                  (2,[0],[1.0])|   (1,[0],[1.0])|    (1,[0],[1.0])|\n",
            "| E1001006| 47|              14|                4|                         4|           42|                3|          2|                 1|                 2|                      12|                          4|                        20|                    2|                 3|                           7|                           7|                      1|                   7|                0|         0.0|                      2.0|                1.0|                1.0|             0.0|                          0.0|           0.0|            0.0| (2,[0],[1.0])|              (5,[2],[1.0])|        (2,[1],[1.0])|        (5,[1],[1.0])|    (18,[0],[1.0])|                  (2,[0],[1.0])|   (1,[0],[1.0])|    (1,[0],[1.0])|\n",
            "| E1001007| 40|               5|                4|                         4|           48|                2|          3|                 1|                 5|                      21|                          3|                        20|                    2|                 3|                          18|                          13|                      1|                  12|                1|         0.0|                      0.0|                0.0|                1.0|             0.0|                          1.0|           1.0|            0.0| (2,[0],[1.0])|              (5,[0],[1.0])|        (2,[0],[1.0])|        (5,[1],[1.0])|    (18,[0],[1.0])|                  (2,[1],[1.0])|       (1,[],[])|    (1,[0],[1.0])|\n",
            "| E1001009| 41|              10|                4|                         2|           73|                2|          5|                 4|                 3|                      15|                          2|                        23|                    2|                 2|                          21|                           6|                     12|                   6|                0|         0.0|                      5.0|                2.0|                3.0|             3.0|                          0.0|           0.0|            0.0| (2,[0],[1.0])|                  (5,[],[])|            (2,[],[])|        (5,[3],[1.0])|    (18,[3],[1.0])|                  (2,[0],[1.0])|   (1,[0],[1.0])|    (1,[0],[1.0])|\n",
            "| E1001010| 60|              16|                4|                         1|           84|                3|          2|                 1|                 8|                      14|                          4|                        10|                    1|                 3|                           2|                           2|                      2|                   2|                0|         0.0|                      2.0|                1.0|                1.0|             0.0|                          0.0|           0.0|            0.0| (2,[0],[1.0])|              (5,[2],[1.0])|        (2,[1],[1.0])|        (5,[1],[1.0])|    (18,[0],[1.0])|                  (2,[0],[1.0])|   (1,[0],[1.0])|    (1,[0],[1.0])|\n",
            "| E1001011| 27|              10|                2|                         4|           32|                3|          3|                 1|                 1|                      21|                          3|                         9|                    4|                 2|                           9|                           7|                      1|                   7|                1|         0.0|                      0.0|                2.0|                2.0|             6.0|                          1.0|           0.0|            0.0| (2,[0],[1.0])|              (5,[0],[1.0])|            (2,[],[])|        (5,[2],[1.0])|    (18,[6],[1.0])|                  (2,[1],[1.0])|   (1,[0],[1.0])|    (1,[0],[1.0])|\n",
            "| E1001016| 50|               8|                4|                         4|           54|                3|          1|                 2|                 7|                      15|                          4|                         4|                    2|                 3|                           2|                           2|                      2|                   2|                0|         0.0|                      2.0|                0.0|                1.0|             8.0|                          0.0|           0.0|            0.0| (2,[0],[1.0])|              (5,[2],[1.0])|        (2,[0],[1.0])|        (5,[1],[1.0])|    (18,[8],[1.0])|                  (2,[0],[1.0])|   (1,[0],[1.0])|    (1,[0],[1.0])|\n",
            "| E1001019| 28|               1|                2|                         1|           67|                1|          1|                 2|                 7|                      13|                          4|                        10|                    4|                 3|                           7|                           7|                      3|                   7|                0|         1.0|                      0.0|                1.0|                2.0|             6.0|                          0.0|           1.0|            1.0| (2,[1],[1.0])|              (5,[0],[1.0])|        (2,[1],[1.0])|        (5,[2],[1.0])|    (18,[6],[1.0])|                  (2,[0],[1.0])|       (1,[],[])|        (1,[],[])|\n",
            "| E1001020| 36|               8|                3|                         1|           63|                4|          3|                 1|                 9|                      14|                          1|                        10|                    2|                 3|                           8|                           7|                      0|                   5|                0|         1.0|                      0.0|                0.0|                2.0|             6.0|                          2.0|           0.0|            0.0| (2,[1],[1.0])|              (5,[0],[1.0])|        (2,[0],[1.0])|        (5,[2],[1.0])|    (18,[6],[1.0])|                      (2,[],[])|   (1,[0],[1.0])|    (1,[0],[1.0])|\n",
            "| E1001021| 38|               1|                3|                         3|           81|                3|          3|                 3|                 4|                      14|                          4|                        10|                    4|                 4|                           1|                           0|                      0|                   0|                0|         1.0|                      0.0|                1.0|                2.0|             6.0|                          0.0|           1.0|            0.0| (2,[1],[1.0])|              (5,[0],[1.0])|        (2,[1],[1.0])|        (5,[2],[1.0])|    (18,[6],[1.0])|                  (2,[0],[1.0])|       (1,[],[])|    (1,[0],[1.0])|\n",
            "| E1001022| 44|              24|                3|                         1|           49|                1|          1|                 3|                 2|                      14|                          3|                         9|                    5|                 3|                           5|                           2|                      1|                   4|                0|         0.0|                      1.0|                1.0|                2.0|             6.0|                          2.0|           0.0|            0.0| (2,[0],[1.0])|              (5,[1],[1.0])|        (2,[1],[1.0])|        (5,[2],[1.0])|    (18,[6],[1.0])|                      (2,[],[])|   (1,[0],[1.0])|    (1,[0],[1.0])|\n",
            "| E1001024| 47|               3|                3|                         4|           49|                3|          4|                 3|                 9|                      12|                          4|                        28|                    2|                 2|                          22|                           2|                     11|                  13|                0|         1.0|                      1.0|                2.0|                1.0|             0.0|                          1.0|           1.0|            0.0| (2,[1],[1.0])|              (5,[1],[1.0])|            (2,[],[])|        (5,[1],[1.0])|    (18,[0],[1.0])|                  (2,[1],[1.0])|       (1,[],[])|    (1,[0],[1.0])|\n",
            "| E1001025| 30|              27|                5|                         3|           99|                3|          2|                 4|                 7|                      23|                          4|                        10|                    2|                 2|                           8|                           7|                      7|                   7|                1|         0.0|                      2.0|                2.0|                1.0|             0.0|                          0.0|           0.0|            0.0| (2,[0],[1.0])|              (5,[2],[1.0])|            (2,[],[])|        (5,[1],[1.0])|    (18,[0],[1.0])|                  (2,[0],[1.0])|   (1,[0],[1.0])|    (1,[0],[1.0])|\n",
            "| E1001027| 29|              10|                3|                         3|           99|                3|          1|                 3|                 1|                      11|                          3|                         1|                    6|                 3|                           1|                           0|                      0|                   0|                0|         0.0|                      0.0|                1.0|                1.0|             8.0|                          0.0|           0.0|            0.0| (2,[0],[1.0])|              (5,[0],[1.0])|        (2,[1],[1.0])|        (5,[1],[1.0])|    (18,[8],[1.0])|                  (2,[0],[1.0])|   (1,[0],[1.0])|    (1,[0],[1.0])|\n",
            "| E1001030| 42|              19|                3|                         3|           57|                4|          1|                 3|                 6|                      12|                          4|                         7|                    2|                 3|                           2|                           2|                      2|                   2|                0|         0.0|                      1.0|                2.0|                2.0|             6.0|                          1.0|           1.0|            1.0| (2,[0],[1.0])|              (5,[1],[1.0])|            (2,[],[])|        (5,[2],[1.0])|    (18,[6],[1.0])|                  (2,[1],[1.0])|       (1,[],[])|        (1,[],[])|\n",
            "| E1001035| 34|               8|                2|                         2|           96|                3|          2|                 3|                 3|                      11|                          4|                        10|                    2|                 3|                           5|                           1|                      4|                   3|                0|         1.0|                      1.0|                1.0|                2.0|             6.0|                          0.0|           0.0|            0.0| (2,[1],[1.0])|              (5,[1],[1.0])|        (2,[1],[1.0])|        (5,[2],[1.0])|    (18,[6],[1.0])|                  (2,[0],[1.0])|   (1,[0],[1.0])|    (1,[0],[1.0])|\n",
            "| E1001038| 39|               3|                3|                         3|           44|                4|          2|                 2|                 9|                      15|                          3|                        12|                    3|                 1|                           8|                           3|                      3|                   6|                0|         1.0|                      5.0|                0.0|                3.0|             5.0|                          0.0|           0.0|            0.0| (2,[1],[1.0])|                  (5,[],[])|        (2,[0],[1.0])|        (5,[3],[1.0])|    (18,[5],[1.0])|                  (2,[0],[1.0])|   (1,[0],[1.0])|    (1,[0],[1.0])|\n",
            "| E1001040| 56|               9|                3|                         3|           81|                3|          4|                 4|                 7|                      11|                          3|                        30|                    1|                 2|                          10|                           7|                      1|                   1|                0|         0.0|                      1.0|                0.0|                2.0|             6.0|                          0.0|           0.0|            0.0| (2,[0],[1.0])|              (5,[1],[1.0])|        (2,[0],[1.0])|        (5,[2],[1.0])|    (18,[6],[1.0])|                  (2,[0],[1.0])|   (1,[0],[1.0])|    (1,[0],[1.0])|\n",
            "| E1001041| 40|               2|                1|                         4|           86|                2|          1|                 4|                 0|                      20|                          4|                         5|                    2|                 2|                           4|                           2|                      2|                   3|                1|         1.0|                      1.0|                1.0|                2.0|             6.0|                          0.0|           1.0|            0.0| (2,[1],[1.0])|              (5,[1],[1.0])|        (2,[1],[1.0])|        (5,[2],[1.0])|    (18,[6],[1.0])|                  (2,[0],[1.0])|       (1,[],[])|    (1,[0],[1.0])|\n",
            "| E1001042| 27|               7|                3|                         4|           55|                2|          2|                 1|                 8|                      19|                          1|                         9|                    2|                 1|                           7|                           6|                      0|                   7|                0|         1.0|                      1.0|                1.0|                2.0|             6.0|                          0.0|           0.0|            0.0| (2,[1],[1.0])|              (5,[1],[1.0])|        (2,[1],[1.0])|        (5,[2],[1.0])|    (18,[6],[1.0])|                  (2,[0],[1.0])|   (1,[0],[1.0])|    (1,[0],[1.0])|\n",
            "+---------+---+----------------+-----------------+--------------------------+-------------+-----------------+-----------+------------------+------------------+------------------------+---------------------------+--------------------------+---------------------+------------------+----------------------------+----------------------------+-----------------------+--------------------+-----------------+------------+-------------------------+-------------------+-------------------+----------------+-----------------------------+--------------+---------------+--------------+---------------------------+---------------------+---------------------+------------------+-------------------------------+----------------+-----------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Define categorical columns to encode\n",
        "categorical_cols = [\"Gender\",\n",
        "                    \"EducationBackground\",\n",
        "                    \"MaritalStatus\",\n",
        "                    \"EmpDepartment\",\n",
        "                    \"EmpJobRole\",\n",
        "                    \"BusinessTravelFrequency\",\n",
        "                    \"OverTime\",\n",
        "                    \"Attrition\"]\n",
        "\n",
        "# Create a list of StringIndexer stages for categorical columns\n",
        "indexers = [StringIndexer(inputCol=col, outputCol=col+\"_index\") for col in categorical_cols]\n",
        "\n",
        "# Create a list of OneHotEncoder stages for indexed categorical columns\n",
        "encoders = [OneHotEncoder(inputCol=col+\"_index\", outputCol=col+\"_encoded\") for col in categorical_cols]\n",
        "\n",
        "# Create a pipeline to execute all indexers and encoders\n",
        "pipeline = Pipeline(stages=indexers + encoders)\n",
        "\n",
        "# Fit and transform the data using the pipeline\n",
        "model = pipeline.fit(df)\n",
        "data_encoded = model.transform(df)\n",
        "\n",
        "# Drop the original categorical columns\n",
        "data_encoded = data_encoded.drop(*categorical_cols)\n",
        "\n",
        "# Show the resulting dataset\n",
        "data_encoded.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BOJeDkVZGna-"
      },
      "source": [
        "MODEL TRAINING AND PREDICTION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1PGaXv_wGiOn",
        "outputId": "02c95d16-6995-43a1-8656-142d8a39c82b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.10/dist-packages (3.5.0)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UYpuVl2jGu74"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "from pyspark.ml.classification import GBTClassifier\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQM0SUvOOwJr",
        "outputId": "1e939a6b-2464-46de-8c84-4c434019e5f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----------------+\n",
            "|PerformanceRating|\n",
            "+-----------------+\n",
            "|                1|\n",
            "|                0|\n",
            "+-----------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.select(\"PerformanceRating\").distinct().show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JrN7hafynuCt"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O84Lt2UoN8Bz",
        "outputId": "50cd947a-00cc-40f8-f613-9498b5b05bb6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 99.49%\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Exclude non-numeric and irrelevant columns\n",
        "feature_columns = [col for col in data_encoded.columns if col not in [\"EmpNumber\", \"Attrition\", \"PerformanceRating\"]]\n",
        "\n",
        "# Create a vector assembler\n",
        "assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n",
        "data_assembled = assembler.transform(data_encoded)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "train_data, test_data = data_assembled.randomSplit([0.8, 0.2], seed=42)\n",
        "\n",
        "# Define a machine learning model (Gradient-Boosted Tree Classifier)\n",
        "gbt_classifier = GBTClassifier(labelCol=\"PerformanceRating\", featuresCol=\"features\", maxIter=10, seed=42)\n",
        "\n",
        "# Train the model\n",
        "\n",
        "\n",
        "model = gbt_classifier.fit(train_data)\n",
        "\n",
        "# Make predictions on the test data\n",
        "predictions = model.transform(test_data)\n",
        "\n",
        "# Evaluate the model's performance\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"PerformanceRating\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "accuracy = evaluator.evaluate(predictions)\n",
        "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "syz4ZEE5oydw"
      },
      "source": [
        "With pipeline\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6XryBEYnowtR",
        "outputId": "e8095202-4aa9-4171-ef60-5858fe8daa6e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 99.49%\n"
          ]
        }
      ],
      "source": [
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.classification import GBTClassifier\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "\n",
        "# Exclude non-numeric and irrelevant columns\n",
        "feature_columns = [col for col in data_encoded.columns if col not in [\"EmpNumber\", \"Attrition\", \"PerformanceRating\"]]\n",
        "\n",
        "# Create a vector assembler\n",
        "assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n",
        "\n",
        "# Define a machine learning model (Gradient-Boosted Tree Classifier)\n",
        "gbt_classifier = GBTClassifier(labelCol=\"PerformanceRating\", featuresCol=\"features\", maxIter=10, seed=42)\n",
        "\n",
        "# Create a pipeline\n",
        "pipeline = Pipeline(stages=[assembler, gbt_classifier])\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "train_data, test_data = data_encoded.randomSplit([0.8, 0.2], seed=42)\n",
        "\n",
        "# Train the model using the pipeline\n",
        "model = pipeline.fit(train_data)\n",
        "\n",
        "# Make predictions on the test data\n",
        "predictions = model.transform(test_data)\n",
        "\n",
        "# Evaluate the model's performance\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"PerformanceRating\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "accuracy = evaluator.evaluate(predictions)\n",
        "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-DehDrNTo7E4"
      },
      "source": [
        "DT without pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZtsErYDMkYvk",
        "outputId": "e8b62baf-cb4d-4704-c447-8880a802432e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 98.77%\n"
          ]
        }
      ],
      "source": [
        "from pyspark.ml.classification import DecisionTreeClassifier\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "\n",
        "# Exclude non-numeric and irrelevant columns\n",
        "feature_columns = [col for col in data_encoded.columns if col not in [\"EmpNumber\", \"Attrition\", \"PerformanceRating\"]]\n",
        "\n",
        "# Create a vector assembler\n",
        "assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n",
        "data_assembled = assembler.transform(data_encoded)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "train_data, test_data = data_assembled.randomSplit([0.8, 0.2], seed=42)\n",
        "\n",
        "# Define a machine learning model (Decision Tree Classifier)\n",
        "dt_classifier = DecisionTreeClassifier(labelCol=\"PerformanceRating\", featuresCol=\"features\", seed=42)  # You can adjust other hyperparameters as needed\n",
        "\n",
        "# Train the model\n",
        "model = dt_classifier.fit(train_data)\n",
        "\n",
        "# Make predictions on the test data\n",
        "predictions = model.transform(test_data)\n",
        "\n",
        "# Evaluate the model's performance\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"PerformanceRating\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "accuracy = evaluator.evaluate(predictions)\n",
        "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fo8RmosfpKA2"
      },
      "source": [
        "DT WITH PIPELINE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iJPtkwQ5pIfZ",
        "outputId": "80ef2895-4c42-4ed0-a59e-aed45fbe9c66"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 98.77%\n"
          ]
        }
      ],
      "source": [
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.classification import DecisionTreeClassifier\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "\n",
        "# Exclude non-numeric and irrelevant columns\n",
        "feature_columns = [col for col in data_encoded.columns if col not in [\"EmpNumber\", \"Attrition\", \"PerformanceRating\"]]\n",
        "\n",
        "# Create a vector assembler\n",
        "assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n",
        "\n",
        "# Define a machine learning model (Decision Tree Classifier)\n",
        "dt_classifier = DecisionTreeClassifier(labelCol=\"PerformanceRating\", featuresCol=\"features\", seed=42)\n",
        "\n",
        "# Create a pipeline\n",
        "pipeline = Pipeline(stages=[assembler, dt_classifier])\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "train_data, test_data = data_encoded.randomSplit([0.8, 0.2], seed=42)\n",
        "\n",
        "# Train the model using the pipeline\n",
        "model = pipeline.fit(train_data)\n",
        "\n",
        "# Make predictions on the test data\n",
        "predictions = model.transform(test_data)\n",
        "\n",
        "# Evaluate the model's performance\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"PerformanceRating\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "accuracy = evaluator.evaluate(predictions)\n",
        "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q8kLxORBpPju"
      },
      "source": [
        "RT without pipeline\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qg0s6d0Pk_iM",
        "outputId": "b12f8953-e7af-414f-fe31-2f36e9f30816"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 91.93%\n"
          ]
        }
      ],
      "source": [
        "from pyspark.ml.classification import LogisticRegression\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "\n",
        "# Exclude non-numeric and irrelevant columns\n",
        "feature_columns = [col for col in data_encoded.columns if col not in [\"EmpNumber\", \"Attrition\", \"PerformanceRating\"]]\n",
        "\n",
        "# Create a vector assembler\n",
        "assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n",
        "data_assembled = assembler.transform(data_encoded)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "train_data, test_data = data_assembled.randomSplit([0.8, 0.2], seed=42)\n",
        "\n",
        "# Define a machine learning model (Logistic Regression Classifier)\n",
        "lr_classifier = LogisticRegression(labelCol=\"PerformanceRating\", featuresCol=\"features\", maxIter=10, regParam=0.01, elasticNetParam=0.8, family=\"multinomial\", fitIntercept=True, standardization=True, predictionCol=\"prediction\", probabilityCol=\"probability\", rawPredictionCol=\"rawPrediction\")\n",
        "\n",
        "# Train the model\n",
        "model = lr_classifier.fit(train_data)\n",
        "\n",
        "# Make predictions on the test data\n",
        "predictions = model.transform(test_data)\n",
        "\n",
        "# Evaluate the model's performance\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"PerformanceRating\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "accuracy = evaluator.evaluate(predictions)\n",
        "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-7OMecFGpTwZ"
      },
      "source": [
        "RT with pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RlpCdYwypeeB",
        "outputId": "ce29492a-2c87-4ac5-db6a-e24e218aa05f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 91.93%\n"
          ]
        }
      ],
      "source": [
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "\n",
        "# Exclude non-numeric and irrelevant columns\n",
        "feature_columns = [col for col in data_encoded.columns if col not in [\"EmpNumber\", \"Attrition\", \"PerformanceRating\"]]\n",
        "\n",
        "# Create a vector assembler\n",
        "assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n",
        "\n",
        "# Define a machine learning model (Logistic Regression Classifier)\n",
        "lr_classifier = LogisticRegression(labelCol=\"PerformanceRating\", featuresCol=\"features\", maxIter=10, regParam=0.01, elasticNetParam=0.8, family=\"multinomial\", fitIntercept=True, standardization=True, predictionCol=\"prediction\", probabilityCol=\"probability\", rawPredictionCol=\"rawPrediction\")\n",
        "\n",
        "# Create a pipeline\n",
        "pipeline = Pipeline(stages=[assembler, lr_classifier])\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "train_data, test_data = data_encoded.randomSplit([0.8, 0.2], seed=42)\n",
        "\n",
        "# Train the model using the pipeline\n",
        "model = pipeline.fit(train_data)\n",
        "\n",
        "# Make predictions on the test data\n",
        "predictions = model.transform(test_data)\n",
        "\n",
        "# Evaluate the model's performance\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"PerformanceRating\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "accuracy = evaluator.evaluate(predictions)\n",
        "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ap_6n9p4lbiO"
      },
      "source": [
        "HYPER PARAMETER TUNING:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "_2VKb9yflZv2",
        "outputId": "92203bab-3968-4a00-c417-434112b89109"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 99.39%\n"
          ]
        }
      ],
      "source": [
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.classification import GBTClassifier\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
        "\n",
        "# Exclude non-numeric and irrelevant columns\n",
        "feature_columns = [col for col in data_encoded.columns if col not in [\"EmpNumber\", \"Attrition\", \"PerformanceRating\"]]\n",
        "\n",
        "# Create a vector assembler\n",
        "assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n",
        "\n",
        "# Define a machine learning model (Gradient-Boosted Tree Classifier)\n",
        "gbt_classifier = GBTClassifier(labelCol=\"PerformanceRating\", featuresCol=\"features\")\n",
        "\n",
        "# Create a pipeline\n",
        "pipeline = Pipeline(stages=[assembler, gbt_classifier])\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "train_data, test_data = data_encoded.randomSplit([0.8, 0.2], seed=42)\n",
        "\n",
        "# Set up a parameter grid for hyperparameter tuning\n",
        "param_grid = ParamGridBuilder() \\\n",
        "    .addGrid(gbt_classifier.maxDepth, [5, 10, 15]) \\\n",
        "    .addGrid(gbt_classifier.maxBins, [32, 64, 128]) \\\n",
        "    .build()\n",
        "\n",
        "# Set up cross-validation with hyperparameter tuning\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"PerformanceRating\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "crossval = CrossValidator(estimator=pipeline,\n",
        "                          estimatorParamMaps=param_grid,\n",
        "                          evaluator=evaluator,\n",
        "                          numFolds=5)\n",
        "\n",
        "# Train the model using the pipeline with hyperparameter tuning\n",
        "best_model = crossval.fit(train_data)\n",
        "\n",
        "# Make predictions on the test data\n",
        "predictions = best_model.transform(test_data)\n",
        "\n",
        "# Evaluate the model's performance\n",
        "accuracy = evaluator.evaluate(predictions)\n",
        "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gwG9VoDOtQ94"
      },
      "source": [
        "DT hyperparameter:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "X5PXuTB8mZVM",
        "outputId": "0d3e5799-ea86-4c91-f811-ee43d7559560"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 99.39%\n",
            "Best Max Depth: 10\n",
            "Best Max Bins: 32\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.classification import DecisionTreeClassifier\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
        "\n",
        "# Exclude non-numeric and irrelevant columns\n",
        "feature_columns = [col for col in data_encoded.columns if col not in [\"EmpNumber\", \"Attrition\", \"PerformanceRating\"]]\n",
        "\n",
        "# Create a vector assembler\n",
        "assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n",
        "\n",
        "# Define a machine learning model (Decision Tree Classifier)\n",
        "dt_classifier = DecisionTreeClassifier(labelCol=\"PerformanceRating\", featuresCol=\"features\", seed=42)\n",
        "\n",
        "# Create a pipeline\n",
        "pipeline = Pipeline(stages=[assembler, dt_classifier])\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "train_data, test_data = data_encoded.randomSplit([0.8, 0.2], seed=42)\n",
        "\n",
        "# Set up a parameter grid for hyperparameter tuning\n",
        "param_grid = ParamGridBuilder() \\\n",
        "    .addGrid(dt_classifier.maxDepth, [5, 10, 15]) \\\n",
        "    .addGrid(dt_classifier.maxBins, [32, 64, 128]) \\\n",
        "    .build()\n",
        "\n",
        "# Set up cross-validation with hyperparameter tuning\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"PerformanceRating\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "crossval = CrossValidator(estimator=pipeline,\n",
        "                          estimatorParamMaps=param_grid,\n",
        "                          evaluator=evaluator,\n",
        "                          numFolds=5)\n",
        "\n",
        "# Train the model using the pipeline with hyperparameter tuning\n",
        "best_model = crossval.fit(train_data)\n",
        "\n",
        "# Make predictions on the test data\n",
        "predictions = best_model.transform(test_data)\n",
        "\n",
        "# Evaluate the model's performance\n",
        "accuracy = evaluator.evaluate(predictions)\n",
        "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
        "\n",
        "# Print the best hyperparameters\n",
        "best_maxDepth = best_model.bestModel.stages[1].getOrDefault(\"maxDepth\")\n",
        "best_maxBins = best_model.bestModel.stages[1].getOrDefault(\"maxBins\")\n",
        "print(f\"Best Max Depth: {best_maxDepth}\")\n",
        "print(f\"Best Max Bins: {best_maxBins}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fy-_S2xPuEbU"
      },
      "source": [
        "RT hyperparameter\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "wH3yPx_jm13h",
        "outputId": "05c3612d-c55a-4e54-dfcd-022f5b7bac39"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 94.89%\n",
            "Best RegParam: 0.01\n",
            "Best ElasticNetParam: 0.0\n",
            "Best Max Iter: 10\n"
          ]
        }
      ],
      "source": [
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
        "\n",
        "# Exclude non-numeric and irrelevant columns\n",
        "feature_columns = [col for col in data_encoded.columns if col not in [\"EmpNumber\", \"Attrition\", \"PerformanceRating\"]]\n",
        "\n",
        "# Create a vector assembler\n",
        "assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n",
        "\n",
        "# Define a machine learning model (Logistic Regression Classifier)\n",
        "lr_classifier = LogisticRegression(labelCol=\"PerformanceRating\", featuresCol=\"features\", maxIter=10, regParam=0.01, elasticNetParam=0.8, family=\"multinomial\", fitIntercept=True, standardization=True, predictionCol=\"prediction\", probabilityCol=\"probability\", rawPredictionCol=\"rawPrediction\")\n",
        "\n",
        "# Create a pipeline\n",
        "pipeline = Pipeline(stages=[assembler, lr_classifier])\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "train_data, test_data = data_encoded.randomSplit([0.8, 0.2], seed=42)\n",
        "\n",
        "# Set up a parameter grid for hyperparameter tuning\n",
        "param_grid = ParamGridBuilder() \\\n",
        "    .addGrid(lr_classifier.regParam, [0.01, 0.1, 1.0]) \\\n",
        "    .addGrid(lr_classifier.elasticNetParam, [0.0, 0.5, 1.0]) \\\n",
        "    .addGrid(lr_classifier.maxIter, [5, 10, 15]) \\\n",
        "    .build()\n",
        "\n",
        "# Set up cross-validation with hyperparameter tuning\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"PerformanceRating\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "crossval = CrossValidator(estimator=pipeline,\n",
        "                          estimatorParamMaps=param_grid,\n",
        "                          evaluator=evaluator,\n",
        "                          numFolds=5)\n",
        "\n",
        "# Train the model using the pipeline with hyperparameter tuning\n",
        "best_model = crossval.fit(train_data)\n",
        "\n",
        "# Make predictions on the test data\n",
        "predictions = best_model.transform(test_data)\n",
        "\n",
        "# Evaluate the model's performance\n",
        "accuracy = evaluator.evaluate(predictions)\n",
        "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
        "\n",
        "# Print the best hyperparameters\n",
        "best_regParam = best_model.bestModel.stages[1].getOrDefault(\"regParam\")\n",
        "best_elasticNetParam = best_model.bestModel.stages[1].getOrDefault(\"elasticNetParam\")\n",
        "best_maxIter = best_model.bestModel.stages[1].getOrDefault(\"maxIter\")\n",
        "print(f\"Best RegParam: {best_regParam}\")\n",
        "print(f\"Best ElasticNetParam: {best_elasticNetParam}\")\n",
        "print(f\"Best Max Iter: {best_maxIter}\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}